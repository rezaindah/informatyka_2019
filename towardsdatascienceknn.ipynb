{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import genesis\n",
    "\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_similarity(self,doc1, doc2):\n",
    "\t\"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
    "\n",
    "\tsynsets1 = self.doc_to_synsets(doc1)\n",
    "\tsynsets2 = self.doc_to_synsets(doc2)\n",
    "\n",
    "\treturn (self.similarity_score(synsets1, synsets2) + self.similarity_score(synsets2, synsets1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_NLC_Classifer():\n",
    "    def __init__(self, k=1, distance_type = 'path'):\n",
    "        self.k = k\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    # This function is used for training\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # This function runs the K(1) nearest neighbour algorithm and\n",
    "    # returns the label with closest match. \n",
    "    def predict(self, x_test):\n",
    "        self.x_test = x_test\n",
    "        y_predict = []\n",
    "\n",
    "        for i in range(len(x_test)):\n",
    "            max_sim = 0\n",
    "            max_index = 0\n",
    "            for j in range(self.x_train.shape[0]):\n",
    "                temp = self.document_similarity(x_test[i], self.x_train[j])\n",
    "                if temp > max_sim:\n",
    "                    max_sim = temp\n",
    "                    max_index = j\n",
    "            y_predict.append(self.y_train[max_index])\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tag(self, tag):\n",
    "        \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
    "        tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "        try:\n",
    "            return tag_dict[tag[0]]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "\n",
    "\tdef doc_to_synsets(self, doc):\n",
    "\t\t\"\"\"\n",
    "\t\t\tReturns a list of synsets in document.\n",
    "\t\t\tTokenizes and tags the words in the document doc.\n",
    "\t\t\tThen finds the first synset for each word/tag combination.\n",
    "\t\tIf a synset is not found for that combination it is skipped.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tdoc: string to be converted\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t\tlist of synsets\n",
    "\t\t\"\"\"\n",
    "\t\ttokens = word_tokenize(doc+' ')\n",
    "\t\t\n",
    "\t\tl = []\n",
    "\t\ttags = nltk.pos_tag([tokens[0] + ' ']) if len(tokens) == 1 else nltk.pos_tag(tokens)\n",
    "\t\t\n",
    "\t\tfor token, tag in zip(tokens, tags):\n",
    "\t\t\tsyntag = self.convert_tag(tag[1])\n",
    "\t\t\tsyns = wn.synsets(token, syntag)\n",
    "\t\t\tif (len(syns) > 0):\n",
    "\t\t\t\tl.append(syns[0])\n",
    "\t\treturn l  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(self, s1, s2, distance_type = 'path'):\n",
    "\t\"\"\"\n",
    "\tCalculate the normalized similarity score of s1 onto s2\n",
    "\tFor each synset in s1, finds the synset in s2 with the largest similarity value.\n",
    "\tSum of all of the largest similarity values and normalize this value by dividing it by the\n",
    "\tnumber of largest similarity values found.\n",
    "\n",
    "\tArgs:\n",
    "\t  s1, s2: list of synsets from doc_to_synsets\n",
    "\n",
    "\tReturns:\n",
    "\t  normalized similarity score of s1 onto s2\n",
    "\t\"\"\"\n",
    "\ts1_largest_scores = []\n",
    "\n",
    "\tfor i, s1_synset in enumerate(s1, 0):\n",
    "\t  max_score = 0\n",
    "\t  for s2_synset in s2:\n",
    "\t\t  if distance_type == 'path':\n",
    "\t\t\t  score = s1_synset.path_similarity(s2_synset, simulate_root = False)\n",
    "\t\t  else:\n",
    "\t\t\tscore = s1_synset.wup_similarity(s2_synset)                  \n",
    "\t\t\tif score != None:\n",
    "\t\t\t  if score > max_score:\n",
    "\t\t\t\t  max_score = score\n",
    "\t  \n",
    "\t  if max_score != 0:\n",
    "\t\t  s1_largest_scores.append(max_score)\n",
    "\n",
    "\tmean_score = np.mean(s1_largest_scores)\n",
    "\t\t \n",
    "\treturn mean_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "KNN_NLC_Classifer instance has no attribute 'document_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-63abd006c290>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdoc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'I like showers'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN_NLC_Classifer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Similarity Score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocument_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: KNN_NLC_Classifer instance has no attribute 'document_similarity'"
     ]
    }
   ],
   "source": [
    "doc1 = 'I like rains'\n",
    "doc2 = 'I like showers'\n",
    "x = KNN_NLC_Classifer()\n",
    "print(\"Test Similarity Score: \", x.document_similarity(doc1, doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
